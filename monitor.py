import os
import json
import logging
import asyncio
import atexit
from datetime import datetime
from pathlib import Path
from telegram import Bot
from dotenv import load_dotenv
import random
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# åˆ›å»ºlogæ–‡ä»¶å¤¹
log_dir = Path('log')
log_dir.mkdir(exist_ok=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('monitor.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class NodeseekMonitor:
    def __init__(self):
        self.bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
        self.chat_id = os.getenv('CHAT_ID')
        self.keywords = os.getenv('KEYWORDS').lower().split(',')
        self.check_interval = int(os.getenv('CHECK_INTERVAL'))
        self.target_url = os.getenv('TARGET_URL')
        self.bot = Bot(token=self.bot_token)
        self.seen_posts_file = 'seen_posts.json'
        self.seen_posts = self.load_seen_posts()
        
        # è®¾ç½®Chromeé€‰é¡¹
        self.chrome_options = Options()
        self.chrome_options.add_argument('--headless')  # æ— ç•Œé¢æ¨¡å¼
        self.chrome_options.add_argument('--disable-gpu')
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        self.chrome_options.add_argument('--disable-infobars')
        self.chrome_options.add_argument('--start-maximized')
        self.chrome_options.add_argument('--disable-extensions')
        self.chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        self.chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # åˆå§‹åŒ–WebDriver
        self.driver = None
        
        # æ³¨å†Œé€€å‡ºå¤„ç†å‡½æ•°
        atexit.register(self.cleanup)

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.driver:
                self.driver.quit()
                self.driver = None
        except Exception as e:
            logging.error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {str(e)}")

    def get_random_user_agent(self):
        """è·å–éšæœºUser-Agent"""
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Edge/120.0.0.0',
        ]
        return random.choice(user_agents)

    def init_driver(self):
        """åˆå§‹åŒ–æˆ–é‡æ–°åˆå§‹åŒ–WebDriver"""
        try:
            if self.driver:
                self.cleanup()
            
            # æ¯æ¬¡åˆå§‹åŒ–æ—¶éšæœºåŒ–User-Agent
            self.chrome_options.add_argument(f'--user-agent={self.get_random_user_agent()}')
            
            self.driver = webdriver.Chrome(
                service=Service(ChromeDriverManager().install()),
                options=self.chrome_options
            )
            
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            self.driver.set_page_load_timeout(30)
            self.driver.set_script_timeout(30)
            
            # è®¾ç½®çª—å£å¤§å°ä¸ºéšæœºå€¼
            width = random.randint(1024, 1920)
            height = random.randint(768, 1080)
            self.driver.set_window_size(width, height)
            
            logging.info("WebDriveråˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logging.error(f"åˆå§‹åŒ–WebDriverå¤±è´¥: {str(e)}")
            raise

    def load_seen_posts(self):
        """åŠ è½½å·²ç»å‘é€è¿‡çš„å¸–å­ID"""
        if Path(self.seen_posts_file).exists():
            try:
                with open(self.seen_posts_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except json.JSONDecodeError:
                logging.error(f"JSONæ–‡ä»¶æŸåï¼Œåˆ›å»ºæ–°çš„è®°å½•")
                return []
        return []

    def save_seen_posts(self):
        """ä¿å­˜å·²å‘é€çš„å¸–å­ID"""
        try:
            with open(self.seen_posts_file, 'w', encoding='utf-8') as f:
                json.dump(self.seen_posts, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logging.error(f"ä¿å­˜å·²å‘é€å¸–å­è®°å½•å¤±è´¥: {str(e)}")

    async def send_telegram_message(self, message):
        """å‘é€Telegramæ¶ˆæ¯"""
        try:
            await self.bot.send_message(
                chat_id=self.chat_id,
                text=message,
                parse_mode='HTML'
            )
            logging.info(f"æ¶ˆæ¯å·²å‘é€: {message}")
        except Exception as e:
            logging.error(f"å‘é€æ¶ˆæ¯å¤±è´¥: {str(e)}")

    def check_keywords(self, text):
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«å…³é”®è¯"""
        text = text.lower()
        matched_keywords = [keyword for keyword in self.keywords if keyword in text]
        if matched_keywords:
            logging.info(f"åŒ¹é…åˆ°å…³é”®è¯: {matched_keywords}")
            return True
        return False

    def save_html_content(self, html):
        """ä¿å­˜HTMLå†…å®¹åˆ°logæ–‡ä»¶å¤¹"""
        # timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        # file_path = log_dir / f'page_{timestamp}.txt'
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"URL: {self.target_url}\n")
                f.write(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("="*50 + "\n")
                f.write(html)
            logging.info(f"é¡µé¢å†…å®¹å·²ä¿å­˜åˆ°: {file_path}")
        except Exception as e:
            logging.error(f"ä¿å­˜é¡µé¢å†…å®¹å¤±è´¥: {str(e)}")

    async def fetch_posts(self):
        """è·å–ç½‘ç«™å¸–å­"""
        try:
            if not self.driver:
                logging.error("WebDriveræœªåˆå§‹åŒ–")
                return []
            
            # è®¿é—®é¡µé¢
            self.driver.get(self.target_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # éšæœºç­‰å¾…ä¸€æ®µæ—¶é—´
            await asyncio.sleep(random.uniform(1, 3))
            
            # è·å–é¡µé¢å†…å®¹
            html = self.driver.page_source
            if not html:
                logging.error("è·å–é¡µé¢å†…å®¹å¤±è´¥")
                return []
                
            logging.info(f"æˆåŠŸè·å–é¡µé¢ï¼Œé•¿åº¦: {len(html)} å­—ç¬¦")
            
            # ä¿å­˜é¡µé¢å†…å®¹åˆ°logæ–‡ä»¶å¤¹
            self.save_html_content(html)
            
            # è§£æé¡µé¢
            soup = BeautifulSoup(html, 'html.parser')
            posts = []
            
            # è®°å½•æ‰¾åˆ°çš„HTMLç»“æ„
            logging.info(f"é¡µé¢æ ‡é¢˜: {soup.title.string if soup.title else 'No title found'}")
            
            # 1. æŸ¥æ‰¾post-list-item
            post_items = soup.find_all('li', class_='post-list-item')
            logging.info(f"æ‰¾åˆ° {len(post_items)} ä¸ªpost-list-item")
            
            # å¤„ç†æ¯ä¸ªpost-list-item
            for post in post_items:
                try:
                    # æŸ¥æ‰¾å¸–å­æ ‡é¢˜é“¾æ¥
                    title_link = post.find('div', class_='post-title').find('a')
                    if not title_link:
                        continue
                        
                    title = title_link.get_text(strip=True)
                    href = title_link.get('href', '')
                    
                    if not title or not href:
                        continue
                    
                    # æ„å»ºå®Œæ•´é“¾æ¥
                    full_link = href if href.startswith('http') else f"{self.target_url.rstrip('/')}{href}"
                    
                    # ä½¿ç”¨é“¾æ¥ä½œä¸ºå”¯ä¸€æ ‡è¯†
                    post_id = href
                    
                    posts.append({
                        'id': post_id,
                        'title': title,
                        'link': full_link
                    })
                    logging.info(f"æˆåŠŸè§£æå¸–å­: {title} | URL: {full_link}")
                    
                except Exception as e:
                    logging.error(f"è§£æå¸–å­æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°post-list-itemï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„ç»“æ„
            if not posts:
                # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„å¸–å­é“¾æ¥
                all_links = soup.find_all('a')
                for link in all_links:
                    href = link.get('href', '')
                    if href and ('/post-' in href or '/t/' in href or '/topic/' in href):
                        title = link.get_text(strip=True)
                        if title:  # å¦‚æœé“¾æ¥æœ‰æ–‡æœ¬å†…å®¹
                            full_link = href if href.startswith('http') else f"{self.target_url.rstrip('/')}{href}"
                            posts.append({
                                'id': href,
                                'title': title,
                                'link': full_link
                            })
                            logging.info(f"æˆåŠŸè§£æå¸–å­(å¤‡ç”¨æ–¹æ³•): {title} | URL: {full_link}")
            
            logging.info(f"æ€»å…±æ‰¾åˆ° {len(posts)} ä¸ªå¸–å­")
            return posts
            
        except Exception as e:
            logging.error(f"è·å–å¸–å­å¤±è´¥: {str(e)}")
            return []

    async def monitor_posts(self):
        """ç›‘æ§å¸–å­çš„ä¸»å‡½æ•°"""
        logging.info("å¼€å§‹ç›‘æ§...")
        logging.info(f"ç›‘æ§å…³é”®è¯: {self.keywords}")
        
        try:
            while True:
                try:
                    # æ¯æ¬¡å¾ªç¯éƒ½é‡æ–°åˆå§‹åŒ–WebDriver
                    self.cleanup()
                    self.init_driver()
                    
                    posts = await self.fetch_posts()
                    for post in posts:
                        if post['id'] not in self.seen_posts and self.check_keywords(post['title']):
                            message = (
                                f"ğŸ”” å‘ç°æ–°å¸–å­!\n\n"
                                f"ğŸ“Œ æ ‡é¢˜: {post['title']}\n"
                                f"ğŸ”— é“¾æ¥: {post['link']}\n"
                                f"â° æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                            )
                            await self.send_telegram_message(message)
                            self.seen_posts.append(post['id'])
                            self.save_seen_posts()

                    # æ¸…ç†å½“å‰çš„WebDriver
                    self.cleanup()
                    
                    # éšæœºåŒ–æ£€æŸ¥é—´éš”
                    actual_interval = self.check_interval + random.randint(-10, 10)
                    logging.info(f"æ£€æŸ¥å®Œæˆï¼Œç­‰å¾… {actual_interval} ç§’åé‡æ–°æ£€æŸ¥...")
                    await asyncio.sleep(actual_interval)
                except asyncio.CancelledError:
                    logging.info("ç›‘æ§ä»»åŠ¡è¢«å–æ¶ˆ")
                    break
                except Exception as e:
                    logging.error(f"ç›‘æ§è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                    self.cleanup()  # ç¡®ä¿æ¸…ç†èµ„æº
                    await asyncio.sleep(60)  # å‡ºé”™åç­‰å¾…1åˆ†é’Ÿå†é‡è¯•
        finally:
            self.cleanup()

async def main():
    monitor = NodeseekMonitor()
    try:
        await monitor.monitor_posts()
    except KeyboardInterrupt:
        logging.info("ç¨‹åºè¢«ç”¨æˆ·ç»ˆæ­¢")
    except Exception as e:
        logging.error(f"ç¨‹åºå¼‚å¸¸ç»ˆæ­¢: {str(e)}")
    finally:
        monitor.cleanup()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logging.info("ç¨‹åºè¢«ç”¨æˆ·ç»ˆæ­¢")
    except Exception as e:
        logging.error(f"ç¨‹åºå¼‚å¸¸ç»ˆæ­¢: {str(e)}") 